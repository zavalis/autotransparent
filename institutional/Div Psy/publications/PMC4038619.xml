<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
  <responseDate>2023-02-07T13:07:53Z</responseDate>
  <request verb="GetRecord" identifier="oai:pubmedcentral.nih.gov:4038619" metadataPrefix="pmc">https:/www.ncbi.nlm.nih.gov/pmc/oai/oai.cgi</request>
  <GetRecord>
    <record>
      <header>
        <identifier>oai:pubmedcentral.nih.gov:4038619</identifier>
        <datestamp>2014-06-05</datestamp>
        <setSpec>plosone</setSpec>
        <setSpec>pmc-open</setSpec>
      </header>
      <metadata>
        <article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xsi:schemaLocation="https://jats.nlm.nih.gov/ns/archiving/1.3/ https://jats.nlm.nih.gov/archiving/1.3/xsd/JATS-archivearticle1-3.xsd" article-type="research-article">
          <front>
            <journal-meta>
              <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
              <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
              <journal-id journal-id-type="publisher-id">plos</journal-id>
              <journal-id journal-id-type="pmc">plosone</journal-id>
              <journal-title-group>
                <journal-title>PLoS ONE</journal-title>
              </journal-title-group>
              <issn pub-type="epub">1932-6203</issn>
              <publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, USA</publisher-loc>
              </publisher>
            </journal-meta>
            <article-meta>
              <article-id pub-id-type="accession">PMC4038619</article-id>
              <article-id pub-id-type="pmcid">PMC4038619</article-id>
              <article-id pub-id-type="pmc-uid">4038619</article-id>
              <article-id pub-id-type="pmid">24874703</article-id>
              <article-id pub-id-type="pmid">24874703</article-id>
              <article-id pub-id-type="publisher-id">PONE-D-13-41339</article-id>
              <article-id pub-id-type="doi">10.1371/journal.pone.0098347</article-id>
              <article-categories>
                <subj-group subj-group-type="heading">
                  <subject>Research Article</subject>
                </subj-group>
                <subj-group subj-group-type="Discipline-v2">
                  <subject>Biology and Life Sciences</subject>
                  <subj-group>
                    <subject>Neuroscience</subject>
                    <subj-group>
                      <subject>Sensory Perception</subject>
                    </subj-group>
                  </subj-group>
                  <subj-group>
                    <subject>Psychology</subject>
                    <subj-group>
                      <subject>Behavior</subject>
                      <subj-group>
                        <subject>Human Performance</subject>
                        <subject>Psychological Adjustment</subject>
                      </subj-group>
                    </subj-group>
                    <subj-group>
                      <subject>Emotions</subject>
                      <subject>Human Relations</subject>
                      <subject>Social Psychology</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v2">
                  <subject>Computer and Information Sciences</subject>
                  <subj-group>
                    <subject>Network Analysis</subject>
                    <subj-group>
                      <subject>Social Networks</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
                <subj-group subj-group-type="Discipline-v2">
                  <subject>Social Sciences</subject>
                  <subj-group>
                    <subject>Sociology</subject>
                    <subj-group>
                      <subject>Social Research</subject>
                      <subject>Social Theory</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </article-categories>
              <title-group>
                <article-title>Odor Valence Linearly Modulates Attractiveness, but Not Age Assessment, of Invariant Facial Features in a Memory-Based Rating Task</article-title>
                <alt-title alt-title-type="running-head">Odors Modulate Attractiveness of Faces</alt-title>
              </title-group>
              <contrib-group>
                <contrib contrib-type="author">
                  <name>
                    <surname>Seubert</surname>
                    <given-names>Janina</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">
                    <sup>1</sup>
                  </xref>
                  <xref ref-type="aff" rid="aff3">
                    <sup>3</sup>
                  </xref>
                  <xref ref-type="corresp" rid="cor1">
                    <sup>*</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Gregory</surname>
                    <given-names>Kristen M.</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">
                    <sup>1</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Chamberland</surname>
                    <given-names>Jessica</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff2">
                    <sup>2</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Dessirier</surname>
                    <given-names>Jean-Marc</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff2">
                    <sup>2</sup>
                  </xref>
                </contrib>
                <contrib contrib-type="author">
                  <name>
                    <surname>Lundström</surname>
                    <given-names>Johan N.</given-names>
                  </name>
                  <xref ref-type="aff" rid="aff1">
                    <sup>1</sup>
                  </xref>
                  <xref ref-type="aff" rid="aff3">
                    <sup>3</sup>
                  </xref>
                  <xref ref-type="aff" rid="aff4">
                    <sup>4</sup>
                  </xref>
                </contrib>
              </contrib-group>
              <aff id="aff1">
                <label>1</label>
                <addr-line>Monell Chemical Senses Center, Philadelphia, Pennsylvania, United States of America</addr-line>
              </aff>
              <aff id="aff2">
                <label>2</label>
                <addr-line>Sensation, Perception &amp; Behavior, Unilever R&amp;D, Trumbull, Connecticut, United States of America</addr-line>
              </aff>
              <aff id="aff3">
                <label>3</label>
                <addr-line>Department of Clinical Neuroscience, Karolinska Institute, Stockholm, Sweden</addr-line>
              </aff>
              <aff id="aff4">
                <label>4</label>
                <addr-line>Department of Psychology, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America</addr-line>
              </aff>
              <contrib-group>
                <contrib contrib-type="editor">
                  <name>
                    <surname>Hummel</surname>
                    <given-names>Thomas</given-names>
                  </name>
                  <role>Editor</role>
                  <xref ref-type="aff" rid="edit1"/>
                </contrib>
              </contrib-group>
              <aff id="edit1">
                <addr-line>Technical University of Dresden Medical School, Germany</addr-line>
              </aff>
              <author-notes>
                <corresp id="cor1">* E-mail: <email>jseubert@monell.org</email></corresp>
                <fn fn-type="COI-statement">
                  <p><bold>Competing Interests: </bold>JS, KMG, and JNL have no competing interests. JMD and JC are affiliated with Unilever R&amp;D, Trumbull, CT, USA. This study was funded in part by an investigator-initiated grant from the Unilever Corporation. There are no patents, products in development or marketed products to declare. This does not alter the authors' adherence to all the PLOS ONE policies on sharing data and materials, as detailed online in the guide for authors.</p>
                </fn>
                <fn fn-type="con">
                  <p>Conceived and designed the experiments: JL JS JMD JC. Performed the experiments: JS KMG. Analyzed the data: JL JS. Wrote the paper: JS. Provided critical revisions of the manuscript: JL JMD.</p>
                </fn>
              </author-notes>
              <pub-date pub-type="collection">
                <year>2014</year>
              </pub-date>
              <pub-date pub-type="epub">
                <day>29</day>
                <month>5</month>
                <year>2014</year>
              </pub-date>
              <volume>9</volume>
              <issue>5</issue>
              <elocation-id>e98347</elocation-id>
              <history>
                <date date-type="received">
                  <day>9</day>
                  <month>10</month>
                  <year>2013</year>
                </date>
                <date date-type="accepted">
                  <day>1</day>
                  <month>5</month>
                  <year>2014</year>
                </date>
              </history>
              <permissions>
                <copyright-statement>© 2014 Seubert et al</copyright-statement>
                <copyright-year>2014</copyright-year>
                <copyright-holder>Seubert et al</copyright-holder>
                <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
                  <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p>
                </license>
              </permissions>
              <abstract>
                <p>Scented cosmetic products are used across cultures as a way to favorably influence one's appearance. While crossmodal effects of odor valence on perceived attractiveness of facial features have been demonstrated experimentally, it is unknown whether they represent a phenomenon specific to affective processing. In this experiment, we presented odors in the context of a face battery with systematic feature manipulations during a speeded response task. Modulatory effects of linear increases of odor valence were investigated by juxtaposing subsequent memory-based ratings tasks – one predominantly affective (attractiveness) and a second, cognitive (age). The linear modulation pattern observed for attractiveness was consistent with additive effects of face and odor appraisal. Effects of odor valence on age perception were not linearly modulated and may be the result of cognitive interference. Affective and cognitive processing of faces thus appear to differ in their susceptibility to modulation by odors, likely as a result of privileged access of olfactory stimuli to affective brain networks. These results are critically discussed with respect to potential biases introduced by the preceding speeded response task.</p>
              </abstract>
              <funding-group>
                <funding-statement>This study was funded in part by an investigator-initiated grant from the Unilever Corporation. JNL is funded by the Knut and Alice Wallenberg Foundation (KAW 2012.0141) and a grant from the Swedish Research Council (VRHS2009-2337). JS is funded by a research fellowship by the German Research Foundation (DFG, SE 2147-1). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
              </funding-group>
              <counts>
                <page-count count="7"/>
              </counts>
            </article-meta>
          </front>
          <body>
            <sec id="s1">
              <title>Introduction</title>
              <p>Inferences of stable personal characteristics during face perception are, to a large extent, derived from so-called invariant perceptual features or semantic codes <xref rid="pone.0098347-Bruce1" ref-type="bibr">[1]</xref>, <xref rid="pone.0098347-Haxby1" ref-type="bibr">[2]</xref>. These features constitute signals of high social and reproductive relevance during human interactions, and behaviors aiming to favorably influence them can be traced back to antiquity <xref rid="pone.0098347-Classen1" ref-type="bibr">[3]</xref>. While manipulations can be achieved directly through visual emphasis or concealment of facial features, indirect manipulations through contextual cues, in particular pleasant fragrances, are very common. The cosmetic industry has long exploited the idea that certain odors enhance personal appearance, resulting in a large selection of fragranced facial and body products. In 2011 alone, the global market demand for these products was estimated at an impressive 425.8 billion US dollars <xref rid="pone.0098347-Small1" ref-type="bibr">[4]</xref>. Only recently, however, studies have begun to experimentally explore the mechanisms by which odors exert an influence on visual perception. In line with experimental evidence indicating that the emotional valence of olfactory cues can affect preference for previously neutral visual stimuli <xref rid="pone.0098347-vanReekum1" ref-type="bibr">[5]</xref>, <xref rid="pone.0098347-deAraujo1" ref-type="bibr">[6]</xref>, <xref rid="pone.0098347-Walla1" ref-type="bibr">[7]</xref>, <xref rid="pone.0098347-Banks1" ref-type="bibr">[8]</xref>, or emotion identification performance <xref rid="pone.0098347-Leppanen1" ref-type="bibr">[9]</xref>, <xref rid="pone.0098347-Seubert1" ref-type="bibr">[10]</xref>, <xref rid="pone.0098347-Zhou1" ref-type="bibr">[11]</xref>, studies have demonstrated that the perception of the attractiveness of facial features can be modulated by concurrent presentation of odors with either a very positive or very negative valence <xref rid="pone.0098347-KirkSmith1" ref-type="bibr">[12]</xref>, <xref rid="pone.0098347-Dematte1" ref-type="bibr">[13]</xref>. Whether these effects are specific to affective processing, however, remains to be explored.</p>
              <p>The present study aimed to dissociate odor-dependent modulation of emotional and cognitive aspects of invariant feature processing. Specifically, response patterns to linear modulation of odor valence and facial feature expression on two different outcome variables, age and attractiveness judgments, were explored. Both represent salient fertility cues; however, attractiveness perception has been preferentially associated with emotional processing, while age perception is thought of as a cognitive process. Attractiveness judgments form early in life, are mostly experience-independent <xref rid="pone.0098347-Chatterjee1" ref-type="bibr">[14]</xref>, <xref rid="pone.0098347-McGraw1" ref-type="bibr">[15]</xref>, and based on configural relationships between individual facial features <xref rid="pone.0098347-Aharon1" ref-type="bibr">[16]</xref>. Extraction and analysis of facial aging cues, on the other hand, constitutes an analytically driven process <xref rid="pone.0098347-Bzdok1" ref-type="bibr">[17]</xref> with a relatively high cognitive load <xref rid="pone.0098347-Habel1" ref-type="bibr">[18]</xref>. In line with these findings, face inversion tasks, which change the holistic appearance of relations between facial components while leaving individual components intact, have typically been shown to disrupt attractiveness perception, but not age processing <xref rid="pone.0098347-Quinn1" ref-type="bibr">[19]</xref>, <xref rid="pone.0098347-Bauml1" ref-type="bibr">[20]</xref>. Taking advantage of the difference in perceptual processing between these tasks, we are investigating whether a similar dissociation can be observed for the influence of olfactory stimulus valence on facial feature perception.</p>
              <p>Most studies to date have investigated multisensory effects of odors using dichotomized visual stimuli and two opposing odor valence conditions, such as one extremely pleasant and one extremely unpleasant odor. Such dichotomies fail to appropriately reflect the perceptual and emotional stimulus space we commonly experience <xref rid="pone.0098347-Bradley1" ref-type="bibr">[21]</xref>, <xref rid="pone.0098347-Khan1" ref-type="bibr">[22]</xref>. Furthermore, they do not permit the analysis of continuous transitions between extreme endpoints of stimulus space, which are highly informative about the underlying perceptual mechanisms: while additive effects between the two modalities suggest a joint representation of stimulus space, non-linear patterns and dominance of one modality over the other suggest separate representations.</p>
              <p>Given the strong linkage between odor and affective processing, we expected to observe dissociable response patterns in age estimation and attractiveness judgments resulting from linear modulations of odor valence. More specifically, we hypothesized that judgment of attractiveness, which relies to a great extent on affective processing, would be linearly affected by the valence of a concurrently presented odor. The cognitive-analytical process of age judgment, however, would be characterized by perceptual dominance of visual feature processing and absence of additive integration.</p>
            </sec>
            <sec sec-type="materials|methods" id="s2">
              <title>Materials and Methods</title>
              <sec id="s2a">
                <title>Ethics Statement</title>
                <p>All participants provided written, informed consent prior to participation, and all aspects of the study were approved by the University of Pennsylvania's Institutional Review Board (IRB) prior to starting the study and performed in accord with the Declaration of Helsinki on Biomedical Studies Involving Human Subjects. In addition, the subject depicted in <xref ref-type="fig" rid="pone-0098347-g001">figure 1</xref> provided written informed consent, as outlined in the PLoS consent form, to publication of their photograph. To adhere to PloS standards for data availability, the dataset used to reach the conclusions drawn in the manuscript is available through the Swedish Vetenskapsrådet digital deposit center (<ext-link ext-link-type="uri" xlink:href="http://snd.gu.se/sv">http://snd.gu.se/sv</ext-link>), along with related metadata and methods, and any additional data required to replicate the reported study findings in their entirety.</p>
                <fig id="pone-0098347-g001" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0098347.g001</object-id>
                  <label>Figure 1</label>
                  <caption>
                    <title>Stimulus Selection and Design.</title>
                    <p><bold>A</bold>. Results of odor pilot study. Valence ratings were acquired for 11 stepwise mixtures between 100% fish odor (unpleasant) and 100% Rose odor (pleasant). Five odors were chosen which perceptually corresponded to equidistant linearly increasing valence percepts (dark grey bars). All five odors were significantly different from each other (*: <italic>p</italic>&lt;.05, **: <italic>p</italic>&lt;.01). Red box indicates odors which were grouped together as “more pleasant” in the factorial analysis, blue box indicates odors which were grouped together as “more unpleasant”. <bold>B</bold>. Illustration of facial morphing procedure. The middle picture illustrates the original image; pictures framed by blue box illustrate increasing features (grouped together for factorial analysis), while pictures in the red box illustrate increasing features. <bold>C</bold>. Experimental Design.</p>
                  </caption>
                  <graphic xlink:href="pone.0098347.g001"/>
                </fig>
              </sec>
              <sec id="s2b">
                <title>Participants</title>
                <p>Twenty-two healthy control subjects were enrolled in the study; of these, four were excluded due to suspected malingering based on performance on the speeded response task (accuracy at chance level as defined by one-sample t-test against average performance of .5). The remaining sample consisted of 18 healthy non-smoking participants (12 women, mean age  = 25, SD = 2.7) who were instructed not to eat or drink anything but water one hour prior to testing and not to wear any scented products on the day of testing. All participants had a functional sense of smell as established by a 16-items 4 alternatives cued odor identification test <xref rid="pone.0098347-Hummel1" ref-type="bibr">[23]</xref> all &gt;11, mean  = 13.44 <italic>SD</italic>±1.19).</p>
              </sec>
              <sec id="s2c">
                <title>Odor Stimuli and Delivery</title>
                <p>Odor stimuli with a linear progression in perceived valence from a mildly unpleasant to a mildly pleasant percept were created using an essential oil with the odor quality of fish (1% cooked fish odor; Symrise AG, Holzminden, Germany) and an essential oil smelling like roses (5% rose odor; Givaudan Inc.), both diluted in 1,2-propanediol (Sigma Aldrich, St. Louis, MO, USA). Iso-intensity of the two stimulus compounds was established in a separate pilot study on a panel of 10 experienced raters by intensity ratings on an identical computerized scale as described below. These two odor concentrations served as endpoints for eleven linear progressive mixture steps ranging from 100% fish odor (most unpleasant stimuli) to 100% rose odor (most pleasant stimuli) with a 50/50%v/v mixture as middle step. Based on a separate pilot study (n = 15, 11 women), five odor concentrations that perceptually corresponded to a linear increase in valence from the two endpoints were selected for the main experiment (see <xref ref-type="fig" rid="pone-0098347-g001">Figure 1A</xref>). This stimulus set allowed us to explore valence-dependent effects using odor stimuli positioned at the mid-range of the odor valence rating scale, a more ecological valid range than using odor stimulus positioned at the two extreme end points.</p>
                <p>All odors were presented using a computer controlled and fully automatic olfactometer operated by the software E-Prime Professional 2.0 (Psychology Software Tools Inc., Pittsburgh, PA). The olfactometer design has been described in detail elsewhere <xref rid="pone.0098347-Lundstrom1" ref-type="bibr">[24]</xref>. In short, a valve control unit regulates the state of the olfactometer's solenoid valves, each of which directs a continuous airstream of 3.0 liters per minute (lpm) into an odor glass reservoir containing 10 ml of the odor in question when triggered by the valve control unit. The odorized headspace is transported to a birhinal nosepiece where one channel serves as a conduit for the odorless control flow. This control flow is directed to the nosepiece in-between odor presentations. In the nosepiece, the flow from the activated channel (odor or control) mixes with a continuous, low-flow airstream (0.5 lpm), adding up to a total airflow of 1.75 lpm per nostril. This continuous airstream masks the tactile cues that might otherwise alert the subject to channel-switching <xref rid="pone.0098347-Boesveldt1" ref-type="bibr">[25]</xref>, <xref rid="pone.0098347-Miller1" ref-type="bibr">[26]</xref>.</p>
              </sec>
              <sec id="s2d">
                <title>Visual Stimuli and Delivery</title>
                <p>A face-only image (see <xref ref-type="fig" rid="pone-0098347-g001">Figure 1B</xref>, bottom left) was acquired from 55 women in the ages 35–50 using a high-resolution Canon EOS-1Ds camera. The images were taken using front-facing poses, with the subjects' hair pulled back from the face, eyes open, and assuming a neutral facial expression. In a second pilot study (n = 16, 7 female), these 55 images were rated for perceived attractiveness and age, as well as absence of emotional expression. Pilot subjects were further given an opportunity to flag images which they did not consider representative of the general population, and images with a high concordance across pilot subjects on this item were not included in the main task. This procedure was adopted to exclude faces that would draw attention towards specific unusual facial features in individual faces which would disproportionally affect the results. The eight final images were perceived to have a neutral emotional expression, were difficult to define in age, and their attractiveness was rated within two standard deviations of the mean in either direction. Individuals in the included images had a mean age of 42.25, and a perceived age of 40.06 (not significantly different from real age).</p>
                <p>Each selected image underwent image manipulation to either increase (henceforth called ‘increased feature conditions’) or decrease (henceforth called ‘decreased feature conditions’) the appearance of wrinkles and blemishes (see <xref ref-type="fig" rid="pone-0098347-g001">Figure 1B</xref>, center). Importantly, by manipulating the faces along this single dimension, we introduced perceptual differences along both of our dependent measures, attractiveness and age perception. A total of four transformations were used, with two increasing the appearance of wrinkles and blemishes, one at a low (−25) and one at a moderate (−50) level, and two decreasing the appearance of these attributes at low (25) and moderate (50) levels. All images were presented on a 19″ TFT screen with an eye-to-screen distance of 100 cm with a visual angle of 9.77° in width and 7.04° in height. Images were presented using the stimulus presentation program E-Prime Professional 2.0 (Psychology Software Tools Inc., Pittsburgh, PA), which also controlled the olfactometer and collected subject responses.</p>
              </sec>
              <sec id="s2e">
                <title>Procedures</title>
                <p>Participants were first presented with an unprocessed image of a face (the reference image) for a total of 1000 ms (see <xref ref-type="fig" rid="pone-0098347-g001">Figure 1C</xref>). At the offset of the target face, odor presentation was initiated and a blank screen was displayed with a random interval between 400 to 600 ms, after which a second image of the same face with increased or decreased features (the altered image) were presented during a maximum of 2000 ms. Participants were asked to make a simple speeded decision whether the face in the altered image looked older or younger than the reference image presented before, using a response pad. Responses within the allotted 2000 ms removed the image, ended the odor presentation, and were followed by a 1000 ms blank image to remove image after effects. This procedure limited the allowed time for feature-based face processing, and second, provided a means to monitor task based attention and identify malingering participants.<xref rid="pone.0098347-Classen1" ref-type="bibr">[3]</xref> Then, one of three questions appeared on the screen. In one third of the trials (pseudo-randomly assigned to reduce demand characteristics), participants had to assess the age, and in one third of the trials, the attractiveness of the individual in the altered image. In another third of trials, they rated the valence of the presented odor. Perceptual ratings were conducted by means of a digital visual analog scale with the anchors “extremely unpleasant”/“extremely pleasant” in the case of odor valence evaluation and “extremely unattractive”/“extremely attractive” in case of face attractiveness evaluation. The scales looked identical in each of the three questions, consisting of a visually continuous blue bar which for each question was subsequently divided into 100 subunits. In the case of the age ratings, the scale was visually anchored by the endpoints “&lt;25” and “&gt;60”, and ticks in steps of 5 years were placed underneath the scale to provide additional orientation and increase ecological validity. Within each question, conditions were matched in the age of the individual actors with no statistical differences between them (all <italic>t</italic>s&lt;.99, all <italic>p</italic>s&gt;.33). The task was repeated eight times for every possible odor (6) and facial transformation category (4) combination rendering a total of 192 trials per participant. To limit odor adaptation and habituation, an average of 12 s (+/−100 ms jitter) inter-trial-interval (ISI) was used and testing was divided into four blocks of equal duration with two minutes rest in-between each testing block.</p>
              </sec>
              <sec id="s2f">
                <title>Data reduction and statistical analyses</title>
                <p>To accommodate differences in variance between the age and attractiveness rating tasks, rating scale results were z-transformed before they were submitted to combined analyses. Categorical effects of modulated facial features and odor valence on attractiveness and age perception, were first analyzed by a factorial approach: for this, we recoded the two most pleasant odors into a “more pleasant” category and the two most unpleasant odors as “more unpleasant” category, excluding the middle (neutral) odor. The resulting odor categories differed significantly from each other in perceived valence (t(17) = 8.04, p&lt;.001), and also differed significantly from the expected neutral valence point of 50 (more pleasant category: mean  = 57.95, t(17) = 4.85, p&lt;.001, more unpleasant category: mean  = 37.90, t(17) = −7.96, p&lt;.001). Similarly, we recoded the modulated faces as either “increased features” (−50, −25 degree of modulation) or “decreased features” (50, 25 degree of modulation) and entered these four variables into a 2×2×2 mixed-effect ANOVA with odor valence, feature strength (amount of wrinkles &amp; blemishes), and task type (attractiveness vs. age) as fixed factors and subject variance as a random factor. Significant interactions were dissected by test-wise ANOVAs and Bonferroni-corrected Tukey post-hoc tests. To determine whether the observed modulations could be explained by linear representations of odor and face manipulations, we coded our visual and olfactory manipulations as linear regressors and conducted linear mixed effect multiple regression analyses which assessed effects of the modulation within each dimension. To control for repeated statistical testing performed on the same dataset, significant effects are reported at a significance level of <italic>p</italic> = .01.</p>
                <p>Reaction time and response data often demonstrate non-spherical distributions, violating the assumptions underlying parametric inference statistics. Therefore, to allow the use of parametric testing, we log-transformed all reaction time data and arcsine-transformed participants' performance scores on the 2AFC age-discrimination task; these steps assured a normalized distribution of our data. Hereby, responses were counted as incorrect if the subjects rated a stronger morph as younger or a weaker morph as older. Nonresponses were excluded from analysis. Further, to account for the interrelatedness of accuracy and reaction time measures manifested in a speed-accuracy tradeoff, we combined these measures into a joint efficiency measure <xref rid="pone.0098347-Rach1" ref-type="bibr">[27]</xref>, <xref rid="pone.0098347-Townsend1" ref-type="bibr">[28]</xref>, <xref rid="pone.0098347-Townsend2" ref-type="bibr">[29]</xref> consisting of the quotient of the transformed accuracy by the transformed reaction time measure. We hypothesized that the degree of difference between the reference image and the altered image would have an effect on task difficulty which would be reflected in higher efficiency rates with increasing differences between the two. We tested this hypothesis in a 2×2 mixed effects ANCOVA, with direction of morphing (older vs younger) and strength of morphing (strong vs weak) as the within-subject factors. Odor valence was included in the model as a linear covariate. All analyses were conducted in the R statistical computing environment (<ext-link ext-link-type="uri" xlink:href="http://www.R-project.org">www.R-project.org</ext-link>), using the nlme package for linear mixed effects models, and the multcomp package for post-hoc tests.</p>
              </sec>
            </sec>
            <sec id="s3">
              <title>Results</title>
              <sec id="s3a">
                <title>Analyses of Attractiveness and Age Rating Scales</title>
                <p>Differential effects of the odor and face manipulations on age and attractiveness were observed using the factorial approach (odor by face by test interaction, F(1,119) = 10.57, p = .002), and persisted in the linear regression analysis (odor by face by test interaction, (t(695) = 2.80, p = .005). To decompose these interactions, separate models were conducted on each rating scale.</p>
              </sec>
              <sec id="s3b">
                <title>Facial Attractiveness Ratings</title>
                <p>Regression over all odor conditions showed a linear relationship between wrinkles and blemishes and attractiveness, (R = .21, p&lt;.001, see <xref ref-type="fig" rid="pone-0098347-g002">figure 2A</xref>). This relationship was reflected in the factorial model [main effect of face, <italic>F</italic>(1,51) = 23.85, <italic>p</italic>&lt;.001]. As predicted, more pleasant odors [main effect of odor, <italic>F</italic>(1,51) = 17.30, <italic>p</italic>&lt;.001] also resulted in higher attractiveness ratings for the altered faces. No interaction between facial morphing and odor valence was observed (<xref ref-type="fig" rid="pone-0098347-g003">Figure 3A</xref>). Investigating the linear modulation across the full stimulus range, additive effects of both experimental modulations were observed: a linear increase of perceived facial attractiveness was predicted both by a linear increase of odor valence, <italic>t</italic>(339) = 5.19, <italic>p</italic>&lt;.001, and a linear decrease of facial feature strength (amount of wrinkles &amp; blemishes), <italic>t</italic>(339) = 7.05, <italic>p</italic>&lt;.001.</p>
                <fig id="pone-0098347-g002" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0098347.g002</object-id>
                  <label>Figure 2</label>
                  <caption>
                    <title>Effects of visual manipulations on attractiveness (A) and age ratings (B) averaged across odorants.</title>
                    <p>Ratings were provided on a visual analog scale consisting of 100 sub segments, which in the case of age was anchored at 25 and 60 for ecological validity. Error Bars indicate +−1 SE. Across all odor conditions, a linear modulation of attractiveness and age (p&lt;.001) were observed.</p>
                  </caption>
                  <graphic xlink:href="pone.0098347.g002"/>
                </fig>
                <fig id="pone-0098347-g003" orientation="portrait" position="float">
                  <object-id pub-id-type="doi">10.1371/journal.pone.0098347.g003</object-id>
                  <label>Figure 3</label>
                  <caption>
                    <title>Results of factorial analyses for categorical effects of odors and facial morphing on attractiveness (A) and age (B) and ratings.</title>
                    <p>Ratings were provided on a visual analog scale consisting of 100 sub segments, which in the case of age was anchored at 25 and 60 for ecological validity. Error Bars indicate +−1 SE, asterisks indicate significant differences as revealed by post hoc t-tests (*  = <italic>p</italic>&lt;.05, **  = <italic>p</italic>&lt;.01, ***  = <italic>p</italic>&lt;.001).</p>
                  </caption>
                  <graphic xlink:href="pone.0098347.g003"/>
                </fig>
              </sec>
              <sec id="s3c">
                <title>Facial Age Ratings</title>
                <p>Feature strength (amount of wrinkles &amp; blemishes) was also found to modulate age ratings, with stronger feature expression being linked to older age perception (R = −.54, p&lt;.001, see <xref ref-type="fig" rid="pone-0098347-g002">figure 2B</xref>). While the factorial analysis reflect this effect (main effect of face [<italic>F</italic>(1,51) = 80.05, <italic>p</italic>&lt;.001]), the effect of odors on age perception was not found to be statistically significant [<italic>F</italic>(1,51) = 4.01, <italic>p</italic> ns], but varied depending on the direction of facial feature modulation [face*odor interaction, <italic>F</italic>(1,51) = 39.01, <italic>p</italic>&lt;.001, see <xref ref-type="fig" rid="pone-0098347-g003">figure 3B</xref>].</p>
                <p>Post-hoc Tukey's tests demonstrated that this interaction was driven by increased and decreased feature morphs being rated significantly differently during more pleasant odor stimulation (p&lt;.001), but not during more unpleasant odor stimulation.</p>
                <p>The mixed regression model supported a linear effect of facial morphing strength, [<italic>t</italic>(339) = −7.48, <italic>p</italic>&lt;.001], but not odor, [<italic>t</italic>(339) = −.1.06, <italic>p</italic> ns], on age ratings. Again, the interaction between face and odor was significant [<italic>t</italic>(339) = —3.23, <italic>p</italic> = .001].</p>
              </sec>
              <sec id="s3d">
                <title>Odor valence ratings</title>
                <p>As expected, the presented odor stimulus type explained variability in the odor valence ratings [main effect of odor, <italic>F</italic>(1,543) = 446.84, <italic>p</italic>&lt;.001]. Strength of facial morphing, however, had no significant effect on odor ratings [<italic>F</italic>(1,543) = 6.42, <italic>p</italic> ns], and no significant interaction between the two variables was observed [<italic>F</italic>(1,543)&lt;.001, <italic>p</italic> ns]. Similarly, the mixed regression model demonstrated a linear positive increase in valence ratings with increasing valence of odor mixtures, <italic>t</italic>(339) = 22.47, <italic>p</italic>&lt;.001. No other significant effects were observed.</p>
              </sec>
              <sec id="s3e">
                <title>Task Performance</title>
                <p>Performance efficiency in the 2AFC task did not differ by direction of facial morphing, and no effect of odorant could be observed. Performance efficiency was, however, significantly greater when faces were more strongly morphed [<italic>F</italic>(1,335) = 41.55, p&lt;.001], thus demonstrating a successful increase in perceived difference between the reference face and the altered images in synchrony with the degree of facial morphing.</p>
              </sec>
            </sec>
            <sec id="s4">
              <title>Discussion</title>
              <p>By applying linear manipulations to odors and invariant facial features, the present study demonstrates that olfactory and visual cues can alter memory-based representations of facial attractiveness in an additive manner. While factorial analyses indicated that concurrent presentation of odors also influenced the representation of facial age, a closer examination of olfactory-visual interactions in a regression model revealed that only the integration pattern observed during attractiveness perception was consistent with the notion of olfactory-visual representation in a joint stimulus space. Given the difference between age and attractiveness judgments in their susceptibility to modulation by odors, we propose that the perceptual mechanisms which underlie olfactory-visual integration of invariant facial features are specific to affective processing.</p>
              <p>Our findings replicate and extend reports from previous studies, which suggest that emotionally-valenced odors have the ability to influence the perceived attractiveness of presented faces <xref rid="pone.0098347-KirkSmith1" ref-type="bibr">[12]</xref>, <xref rid="pone.0098347-Dematte1" ref-type="bibr">[13]</xref> even when the subject is instructed to focus on the face alone. While previous studies have looked at extreme cases of odor valence and investigated effects on one outcome variable, we can demonstrate here that increases in observed odor valence are specific to attractiveness perception and translate directly onto ratings in an additive fashion: as expected, modulations of both visual properties and odor valence were associated with linear effects on attractiveness perception.</p>
              <p>While multisensory integration at the early perceptual level is usually associated with superadditive effects <xref rid="pone.0098347-Ethofer1" ref-type="bibr">[30]</xref>, <xref rid="pone.0098347-Stein1" ref-type="bibr">[31]</xref>, affective responses to multisensory input are thought to be independent from the availability of attentional resources <xref rid="pone.0098347-Vroomen1" ref-type="bibr">[32]</xref> and thus characterized by linear summation. Given the strong affective component of attractiveness ratings, which tend to cluster along a valence dimension subserving approach and avoidance behavior <xref rid="pone.0098347-Oosterhof1" ref-type="bibr">[33]</xref>, the observed linear integration pattern thus represents a typical response to affective evaluation of multisensory input. This combination into a joint stimulus space is thought to result from supramodal affective back-projections from prefrontal cortex, which have been shown to modulate emotional object evaluations <xref rid="pone.0098347-Barrett1" ref-type="bibr">[34]</xref>. Equally, the strong anatomical overlap between affective prefrontal areas and secondary olfactory cortex <xref rid="pone.0098347-Seubert2" ref-type="bibr">[35]</xref>, provides a unique link between olfactory object and valence perception <xref rid="pone.0098347-Zald1" ref-type="bibr">[36]</xref>, <xref rid="pone.0098347-Rolls1" ref-type="bibr">[37]</xref>, <xref rid="pone.0098347-Olofsson1" ref-type="bibr">[38]</xref>. Taken together, our findings provide strong support for affectively-mediated olfactory influences on face perception, which are unique to evaluation tasks possessing a shared emotional component.</p>
              <p>By contrast, the effect of odors on age perception demonstrated an interaction on the factorial level. While face morphs of opposite direction were rated as similar in age under more unpleasant odor conditions, they were clearly rated as different in age under more pleasant odor conditions. Linear regression analysis confirmed the interaction pattern and linear judgment of facial aging cues, and did not support a linear combination of odors and faces. Age perception has been reported to represent a higher cognitive load relative to emotion-based evaluations <xref rid="pone.0098347-Habel1" ref-type="bibr">[18]</xref>, and various studies have to date reported an interference of emotionally emotionally-valenced stimulus material with effortful cognitive processing <xref rid="pone.0098347-Dolcos1" ref-type="bibr">[39]</xref>, <xref rid="pone.0098347-Kristjansson1" ref-type="bibr">[40]</xref>, <xref rid="pone.0098347-Pessoa1" ref-type="bibr">[41]</xref>. Consistent with evidence suggesting that age-perception is a learned higher-order cognitive mechanism <xref rid="pone.0098347-Chatterjee1" ref-type="bibr">[14]</xref>, <xref rid="pone.0098347-McGraw1" ref-type="bibr">[15]</xref>, we therefore propose that in the context of age-perception, unpleasant odors may constitute a threat signal which elicits automatic allocation of attention to affective cues <xref rid="pone.0098347-Forscher1" ref-type="bibr">[42]</xref>, so emotionally-irrelevant aging cues likely lose salience by comparison. During pleasant odor stimulation, however, more attentional resources might be allocated to the face perception task, resulting in an increased difference in perceived age between increased and decreased feature conditions. These findings are consistent with the idea that odor and attractiveness perception, but not odor and age perception, feed into a common affective neural system and therefore jointly affect behavioral responses. Future studies will need to focus on manipulating the attentional load and distraction components in order to more comprehensively describe the demonstrated interaction pattern, and specifically test hypotheses relating to the neural mechanisms underlying the observed effects.</p>
              <p>Our study design resulted in a number of inherent drawbacks which should be taken into consideration. Most importantly, it is not possible in the context of the present experiment to quantify the extent and direction of a potential bias introduced by our choice of speeded response task during presentation of the morphed image. A two-step response format was adopted to effectively limit analytical exploration times of the faces to a time that would not allow for extended detailed inspection of the visual images. This resulted in a higher difficulty level for the memory-based rating task, which is a prerequisite for the observation of multisensory integration effects. However, given the conceptual similarity between the older/younger decision in the speeded task and the subsequent rating, we cannot rule out that our results may have been affected by conceptual priming effects on age, but not attractiveness, decisions during encoding. Given that the homogeneity of the facial battery used in this task restricted us to this task choice, future studies should use a more diverse battery to open up possibilities for modifications of the experimental design, and a detailed investigation of the influence of the choice of speeded response task on the outcome of these ratings. Doing so would further allow for investigations of sex-dependent differences in the study sample or stimulus material, as have been suggested by previous studies <xref rid="pone.0098347-Pollatos1" ref-type="bibr">[43]</xref>. To optimize our experimental power towards the detection of linear effects, we opted to prioritize a higher number of repetitions for crossmodal conditions and not include a condition that showed the unmorphed picture as the target image (ie. a visual stimulus repetition), and a no odor condition without concurrent face presentation. As a result, we do not have unimodal reference ratings of odors or face stimuli from our study sample. We do not, however, have any reason to suspect a systematic variation between the study and pilot samples. Moreover, our study was restricted to a stimulus set of female faces.</p>
              <p>Finally, due to increasing evidence for specific odor associations across the life span <xref rid="pone.0098347-Miller2" ref-type="bibr">[44]</xref>, <xref rid="pone.0098347-Lundstrom2" ref-type="bibr">[45]</xref>, <xref rid="pone.0098347-Mitro1" ref-type="bibr">[46]</xref>, we chose to restrict the age range of the face battery to middle-aged individuals. Future studies should investigate whether these effects may be modulated by the age range of both the facial stimulus battery and the observers.</p>
              <p>In conclusion, our study demonstrates that linear olfactory enhancement of facial perceptual judgments occurs for attractiveness, but not age ratings. These integration mechanisms are unlikely to reflect basic bottom-up sensory processes, but rather, valence-dependent supramodal associations, analogous to the perceptual principles regulating audio-visual emotional integration <xref rid="pone.0098347-Vroomen2" ref-type="bibr">[47]</xref>, <xref rid="pone.0098347-Barrett2" ref-type="bibr">[48]</xref>. Olfactory influences on analytical cognitive processing of faces, as observed in age judgments, follow a pattern that is indicative of cognitive interference. While olfactory effects on person perception have long been neglected in the laboratory, this study stresses that such effects likely have an important effect on the affective connotation of real-life social interactions and deserve further attention.</p>
            </sec>
          </body>
          <back>
            <ack>
              <p>The authors would like to thank Lauren Varallo for her help during data acquisition and Givaudan Inc. for kindly providing us with a sample of the rose essential oil.</p>
            </ack>
            <ref-list>
              <title>References</title>
              <ref id="pone.0098347-Bruce1">
                <label>1</label>
                <mixed-citation publication-type="journal"><name><surname>Bruce</surname><given-names>V</given-names></name>, <name><surname>Young</surname><given-names>A</given-names></name> (<year>1986</year>) <article-title>Understanding face recognition</article-title>. <source>Br J Psychol</source>
<volume>77 (Pt 3)</volume>: <fpage>305</fpage>–<lpage>327</lpage>.<pub-id pub-id-type="pmid">3756376</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Haxby1">
                <label>2</label>
                <mixed-citation publication-type="journal"><name><surname>Haxby</surname><given-names>JV</given-names></name>, <name><surname>Hoffman</surname><given-names>EA</given-names></name>, <name><surname>Gobbini</surname><given-names>MI</given-names></name> (<year>2000</year>) <article-title>The distributed human neural system for face perception</article-title>. <source>Trends Cogn Sci</source>
<volume>4</volume>: <fpage>223</fpage>–<lpage>233</lpage>.<pub-id pub-id-type="pmid">10827445</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Classen1">
                <label>3</label>
                <mixed-citation publication-type="othor">Classen C, Howes D, Synnott A (1994) Aroma: The cultural history of smell: Routledge. 256 p.</mixed-citation>
              </ref>
              <ref id="pone.0098347-Small1">
                <label>4</label>
                <mixed-citation publication-type="other">Small DM, Green BG (2012) A Proposed Model of a Flavor Modality. In: Murray MM, Wallace MT, The Neural Bases of Multisensory Processes. Boca Raton (FL).</mixed-citation>
              </ref>
              <ref id="pone.0098347-vanReekum1">
                <label>5</label>
                <mixed-citation publication-type="journal"><name><surname>van Reekum</surname><given-names>CM</given-names></name>, <name><surname>vann de Berg</surname><given-names>H</given-names></name>, <name><surname>Frijda</surname><given-names>NH</given-names></name> (<year>1999</year>) <article-title>Cross-modal Preference Acquisition: Evaluative Conditioning of Pictures by Affective Olfactory and Auditory Cues</article-title>. <source>Cognition &amp; Emotion</source>
<volume>13</volume>: <fpage>831</fpage>–<lpage>836</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0098347-deAraujo1">
                <label>6</label>
                <mixed-citation publication-type="journal"><name><surname>de Araujo</surname><given-names>IE</given-names></name>, <name><surname>Rolls</surname><given-names>ET</given-names></name>, <name><surname>Velazco</surname><given-names>MI</given-names></name>, <name><surname>Margot</surname><given-names>C</given-names></name>, <name><surname>Cayeux</surname><given-names>I</given-names></name> (<year>2005</year>) <article-title>Cognitive modulation of olfactory processing</article-title>. <source>Neuron</source>
<volume>46</volume>: <fpage>671</fpage>–<lpage>679</lpage>.<pub-id pub-id-type="pmid">15944134</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Walla1">
                <label>7</label>
                <mixed-citation publication-type="journal"><name><surname>Walla</surname><given-names>P</given-names></name>, <name><surname>Deecke</surname><given-names>L</given-names></name> (<year>2010</year>) <article-title>Odours influence visually induced emotion: behavior and neuroimaging</article-title>. <source>Sensors (Basel)</source>
<volume>10</volume>: <fpage>8185</fpage>–<lpage>8197</lpage>.<pub-id pub-id-type="pmid">22163649</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Banks1">
                <label>8</label>
                <mixed-citation publication-type="journal"><name><surname>Banks</surname><given-names>SJ</given-names></name>, <name><surname>Ng</surname><given-names>V</given-names></name>, <name><surname>Jones-Gotman</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Does good+good = better? A pilot study on the effect of combining hedonically valenced smells and images</article-title>. <source>Neurosci Lett</source>
<volume>514</volume>: <fpage>71</fpage>–<lpage>76</lpage>.<pub-id pub-id-type="pmid">22395085</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Leppanen1">
                <label>9</label>
                <mixed-citation publication-type="journal"><name><surname>Leppanen</surname><given-names>JM</given-names></name>, <name><surname>Hietanen</surname><given-names>JK</given-names></name> (<year>2003</year>) <article-title>Affect and face perception: odors modulate the recognition advantage of happy faces</article-title>. <source>Emotion</source>
<volume>3</volume>: <fpage>315</fpage>–<lpage>326</lpage>.<pub-id pub-id-type="pmid">14674826</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Seubert1">
                <label>10</label>
                <mixed-citation publication-type="journal"><name><surname>Seubert</surname><given-names>J</given-names></name>, <name><surname>Kellermann</surname><given-names>T</given-names></name>, <name><surname>Loughead</surname><given-names>J</given-names></name>, <name><surname>Boers</surname><given-names>F</given-names></name>, <name><surname>Brensinger</surname><given-names>C</given-names></name>, <etal>et al</etal> (<year>2010</year>) <article-title>Processing of disgusted faces is facilitated by odor primes: a functional MRI study</article-title>. <source>Neuroimage</source>
<volume>53</volume>: <fpage>746</fpage>–<lpage>756</lpage>.<pub-id pub-id-type="pmid">20627130</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Zhou1">
                <label>11</label>
                <mixed-citation publication-type="journal"><name><surname>Zhou</surname><given-names>W</given-names></name>, <name><surname>Chen</surname><given-names>D</given-names></name> (<year>2009</year>) <article-title>Fear-related chemosignals modulate recognition of fear in ambiguous facial expressions</article-title>. <source>Psychological science</source>
<volume>20</volume>: <fpage>177</fpage>–<lpage>183</lpage>.<pub-id pub-id-type="pmid">19170944</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-KirkSmith1">
                <label>12</label>
                <mixed-citation publication-type="book">Kirk-Smith MD, Booth DA (1990) The effect of five odorants on mood and assessment of other people. In: MacDonald DW, Muller-Schwarze D, Natynczuk, S.E., Chemical Signals in Vertebrates. Oxford: Oxford University Press. pp. 48–54.</mixed-citation>
              </ref>
              <ref id="pone.0098347-Dematte1">
                <label>13</label>
                <mixed-citation publication-type="journal"><name><surname>Dematte</surname><given-names>ML</given-names></name>, <name><surname>Osterbauer</surname><given-names>R</given-names></name>, <name><surname>Spence</surname><given-names>C</given-names></name> (<year>2007</year>) <article-title>Olfactory cues modulate facial attractiveness</article-title>. <source>Chem Senses</source>
<volume>32</volume>: <fpage>603</fpage>–<lpage>610</lpage>.<pub-id pub-id-type="pmid">17507456</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Chatterjee1">
                <label>14</label>
                <mixed-citation publication-type="journal"><name><surname>Chatterjee</surname><given-names>A</given-names></name>, <name><surname>Thomas</surname><given-names>A</given-names></name>, <name><surname>Smith</surname><given-names>SE</given-names></name>, <name><surname>Aguirre</surname><given-names>GK</given-names></name> (<year>2009</year>) <article-title>The neural response to facial attractiveness</article-title>. <source>Neuropsychology</source>
<volume>23</volume>: <fpage>135</fpage>–<lpage>143</lpage>.<pub-id pub-id-type="pmid">19254086</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-McGraw1">
                <label>15</label>
                <mixed-citation publication-type="journal"><name><surname>McGraw</surname><given-names>KO</given-names></name>, <name><surname>Durm</surname><given-names>MW</given-names></name>, <name><surname>Durnam</surname><given-names>MR</given-names></name> (<year>1989</year>) <article-title>The relative salience of sex, race, age, and glasses in children's social perception</article-title>. <source>J Genet Psychol</source>
<volume>150</volume>: <fpage>251</fpage>–<lpage>267</lpage>.<pub-id pub-id-type="pmid">2809573</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Aharon1">
                <label>16</label>
                <mixed-citation publication-type="journal"><name><surname>Aharon</surname><given-names>I</given-names></name>, <name><surname>Etcoff</surname><given-names>N</given-names></name>, <name><surname>Ariely</surname><given-names>D</given-names></name>, <name><surname>Chabris</surname><given-names>CF</given-names></name>, <name><surname>O'Connor</surname><given-names>E</given-names></name>, <etal>et al</etal> (<year>2001</year>) <article-title>Beautiful faces have variable reward value: fMRI and behavioral evidence</article-title>. <source>Neuron</source>
<volume>32</volume>: <fpage>537</fpage>–<lpage>551</lpage>.<pub-id pub-id-type="pmid">11709163</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Bzdok1">
                <label>17</label>
                <mixed-citation publication-type="journal"><name><surname>Bzdok</surname><given-names>D</given-names></name>, <name><surname>Langner</surname><given-names>R</given-names></name>, <name><surname>Hoffstaedter</surname><given-names>F</given-names></name>, <name><surname>Turetsky</surname><given-names>BI</given-names></name>, <name><surname>Zilles</surname><given-names>K</given-names></name>, <etal>et al</etal> (<year>2012</year>) <article-title>The modular neuroarchitecture of social judgments on faces</article-title>. <source>Cereb Cortex</source>
<volume>22</volume>: <fpage>951</fpage>–<lpage>961</lpage>.<pub-id pub-id-type="pmid">21725038</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Habel1">
                <label>18</label>
                <mixed-citation publication-type="journal"><name><surname>Habel</surname><given-names>U</given-names></name>, <name><surname>Windischberger</surname><given-names>C</given-names></name>, <name><surname>Derntl</surname><given-names>B</given-names></name>, <name><surname>Robinson</surname><given-names>S</given-names></name>, <name><surname>Kryspin-Exner</surname><given-names>I</given-names></name>, <etal>et al</etal> (<year>2007</year>) <article-title>Amygdala activation and facial expressions: explicit emotion discrimination versus implicit emotion processing</article-title>. <source>Neuropsychologia</source>
<volume>45</volume>: <fpage>2369</fpage>–<lpage>2377</lpage>.<pub-id pub-id-type="pmid">17408704</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Quinn1">
                <label>19</label>
                <mixed-citation publication-type="journal"><name><surname>Quinn</surname><given-names>KA</given-names></name>, <name><surname>Macrae</surname><given-names>CN</given-names></name> (<year>2005</year>) <article-title>Categorizing others: the dynamics of person construal</article-title>. <source>J Pers Soc Psychol</source>
<volume>88</volume>: <fpage>467</fpage>–<lpage>479</lpage>.<pub-id pub-id-type="pmid">15740440</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Bauml1">
                <label>20</label>
                <mixed-citation publication-type="journal"><name><surname>Bauml</surname><given-names>KH</given-names></name> (<year>1994</year>) <article-title>Upright versus upside-down faces: how interface attractiveness varies with orientation</article-title>. <source>Percept Psychophys</source>
<volume>56</volume>: <fpage>163</fpage>–<lpage>172</lpage>.<pub-id pub-id-type="pmid">7971117</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Bradley1">
                <label>21</label>
                <mixed-citation publication-type="journal"><name><surname>Bradley</surname><given-names>MM</given-names></name>, <name><surname>Lang</surname><given-names>PJ</given-names></name> (<year>1994</year>) <article-title>Measuring emotion: the Self-Assessment Manikin and the Semantic Differential</article-title>. <source>J Behav Ther Exp Psychiatry</source>
<volume>25</volume>: <fpage>49</fpage>–<lpage>59</lpage>.<pub-id pub-id-type="pmid">7962581</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Khan1">
                <label>22</label>
                <mixed-citation publication-type="journal"><name><surname>Khan</surname><given-names>RM</given-names></name>, <name><surname>Luk</surname><given-names>CH</given-names></name>, <name><surname>Flinker</surname><given-names>A</given-names></name>, <name><surname>Aggarwal</surname><given-names>A</given-names></name>, <name><surname>Lapid</surname><given-names>H</given-names></name>, <etal>et al</etal> (<year>2007</year>) <article-title>Predicting odor pleasantness from odorant structure: pleasantness as a reflection of the physical world</article-title>. <source>J Neurosci</source>
<volume>27</volume>: <fpage>10015</fpage>–<lpage>10023</lpage>.<pub-id pub-id-type="pmid">17855616</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Hummel1">
                <label>23</label>
                <mixed-citation publication-type="journal"><name><surname>Hummel</surname><given-names>T</given-names></name>, <name><surname>Konnerth</surname><given-names>CG</given-names></name>, <name><surname>Rosenheim</surname><given-names>K</given-names></name>, <name><surname>Kobal</surname><given-names>G</given-names></name> (<year>2001</year>) <article-title>Screening of olfactory function with a four-minute odor identification test: reliability, normative data, and investigations in patients with olfactory loss</article-title>. <source>The Annals of otology, rhinology, and laryngology</source>
<volume>110</volume>: <fpage>976</fpage>–<lpage>981</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0098347-Lundstrom1">
                <label>24</label>
                <mixed-citation publication-type="journal"><name><surname>Lundstrom</surname><given-names>JN</given-names></name>, <name><surname>Gordon</surname><given-names>AR</given-names></name>, <name><surname>Alden</surname><given-names>EC</given-names></name>, <name><surname>Boesveldt</surname><given-names>S</given-names></name>, <name><surname>Albrecht</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>Methods for building an inexpensive computer-controlled olfactometer for temporally-precise experiments</article-title>. <source>Int J Psychophysiol</source>
<volume>78</volume>: <fpage>179</fpage>–<lpage>189</lpage>.<pub-id pub-id-type="pmid">20688109</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Boesveldt1">
                <label>25</label>
                <mixed-citation publication-type="journal"><name><surname>Boesveldt</surname><given-names>S</given-names></name>, <name><surname>Frasnelli</surname><given-names>J</given-names></name>, <name><surname>Gordon</surname><given-names>AR</given-names></name>, <name><surname>Lundstrom</surname><given-names>JN</given-names></name> (<year>2010</year>) <article-title>The fish is bad: Negative food odors elicit faster and more accurate reactions than other odors</article-title>. <source>Biol Psychol</source>
<volume>84</volume>: <fpage>313</fpage>–<lpage>317</lpage>.<pub-id pub-id-type="pmid">20227457</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Miller1">
                <label>26</label>
                <mixed-citation publication-type="journal"><name><surname>Miller</surname><given-names>SS</given-names></name>, <name><surname>Gordon</surname><given-names>AR</given-names></name>, <name><surname>Olsson</surname><given-names>MJ</given-names></name>, <name><surname>Lundstrom</surname><given-names>JN</given-names></name>, <name><surname>Dalton</surname><given-names>P</given-names></name> (<year>2013</year>) <article-title>Mind over age—stereotype activation and olfactory function</article-title>. <source>Chem Senses</source>
<volume>38</volume>: <fpage>167</fpage>–<lpage>174</lpage>.<pub-id pub-id-type="pmid">23118205</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Rach1">
                <label>27</label>
                <mixed-citation publication-type="journal"><name><surname>Rach</surname><given-names>S</given-names></name>, <name><surname>Diederich</surname><given-names>A</given-names></name>, <name><surname>Colonius</surname><given-names>H</given-names></name> (<year>2011</year>) <article-title>On quantifying multisensory interaction effects in reaction time and detection rate</article-title>. <source>Psychol Res</source>
<volume>75</volume>: <fpage>77</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">20512352</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Townsend1">
                <label>28</label>
                <mixed-citation publication-type="book">Townsend JT, Ashby FG (1978) Methods of modeling capacity in simple processing systems. In: Castellan J, Restle F, Cognitive theory. Hillsdale, NJ: Erlbaum. pp. 200–239.</mixed-citation>
              </ref>
              <ref id="pone.0098347-Townsend2">
                <label>29</label>
                <mixed-citation publication-type="book">Townsend JT, Ashby FG (1983) Stochastic modeling of elementary psychological processes. Cambridge: Cambridge University Press.</mixed-citation>
              </ref>
              <ref id="pone.0098347-Ethofer1">
                <label>30</label>
                <mixed-citation publication-type="journal"><name><surname>Ethofer</surname><given-names>T</given-names></name>, <name><surname>Pourtois</surname><given-names>G</given-names></name>, <name><surname>Wildgruber</surname><given-names>D</given-names></name> (<year>2006</year>) <article-title>Investigating audiovisual integration of emotional signals in the human brain</article-title>. <source>Prog Brain Res</source>
<volume>156</volume>: <fpage>345</fpage>–<lpage>361</lpage>.<pub-id pub-id-type="pmid">17015090</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Stein1">
                <label>31</label>
                <mixed-citation publication-type="book">Stein BE, Meredith MA (1993) Merging of Senses Cambridge, MA: MIT Press.</mixed-citation>
              </ref>
              <ref id="pone.0098347-Vroomen1">
                <label>32</label>
                <mixed-citation publication-type="journal"><name><surname>Vroomen</surname><given-names>J</given-names></name>, <name><surname>Driver</surname><given-names>J</given-names></name>, <name><surname>de Gelder</surname><given-names>B</given-names></name> (<year>2001</year>) <article-title>Is cross-modal integration of emotional expressions independent of attentional resources?</article-title>
<source>Cogn Affect Behav Neurosci</source>
<volume>1</volume>: <fpage>382</fpage>–<lpage>387</lpage>.<pub-id pub-id-type="pmid">12467089</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Oosterhof1">
                <label>33</label>
                <mixed-citation publication-type="journal"><name><surname>Oosterhof</surname><given-names>NN</given-names></name>, <name><surname>Todorov</surname><given-names>A</given-names></name> (<year>2008</year>) <article-title>The functional basis of face evaluation</article-title>. <source>Proc Natl Acad Sci U S A</source>
<volume>105</volume>: <fpage>11087</fpage>–<lpage>11092</lpage>.<pub-id pub-id-type="pmid">18685089</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Barrett1">
                <label>34</label>
                <mixed-citation publication-type="journal"><name><surname>Barrett</surname><given-names>LF</given-names></name>, <name><surname>Bar</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>See it with feeling: affective predictions during object perception</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>
<volume>364</volume>: <fpage>1325</fpage>–<lpage>1334</lpage>.<pub-id pub-id-type="pmid">19528014</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Seubert2">
                <label>35</label>
                <mixed-citation publication-type="journal"><name><surname>Seubert</surname><given-names>J</given-names></name>, <name><surname>Freiherr</surname><given-names>J</given-names></name>, <name><surname>Djordjevic</surname><given-names>J</given-names></name>, <name><surname>Lundstrom</surname><given-names>JN</given-names></name> (<year>2012</year>) <article-title>Statistical localization of human olfactory cortex</article-title>. <source>NeuroImage</source>
<volume>66C</volume>: <fpage>333</fpage>–<lpage>342</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0098347-Zald1">
                <label>36</label>
                <mixed-citation publication-type="journal"><name><surname>Zald</surname><given-names>DH</given-names></name>, <name><surname>Pardo</surname><given-names>JV</given-names></name> (<year>1997</year>) <article-title>Emotion, olfaction, and the human amygdala: amygdala activation during aversive olfactory stimulation</article-title>. <source>Proc Natl Acad Sci U S A</source>
<volume>94</volume>: <fpage>4119</fpage>–<lpage>4124</lpage>.<pub-id pub-id-type="pmid">9108115</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Rolls1">
                <label>37</label>
                <mixed-citation publication-type="journal"><name><surname>Rolls</surname><given-names>ET</given-names></name> (<year>2004</year>) <article-title>Convergence of sensory systems in the orbitofrontal cortex in primates and brain design for emotion</article-title>. <source>Anat Rec A Discov Mol Cell Evol Biol</source>
<volume>281</volume>: <fpage>1212</fpage>–<lpage>1225</lpage>.<pub-id pub-id-type="pmid">15470678</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Olofsson1">
                <label>38</label>
                <mixed-citation publication-type="journal"><name><surname>Olofsson</surname><given-names>JK</given-names></name>, <name><surname>Bowman</surname><given-names>NE</given-names></name>, <name><surname>Khatibi</surname><given-names>K</given-names></name>, <name><surname>Gottfried</surname><given-names>JA</given-names></name> (<year>2012</year>) <article-title>A time-based account of the perception of odor objects and valences</article-title>. <source>Psychological science</source>
<volume>23</volume>: <fpage>1224</fpage>–<lpage>1232</lpage>.<pub-id pub-id-type="pmid">22961773</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Dolcos1">
                <label>39</label>
                <mixed-citation publication-type="journal"><name><surname>Dolcos</surname><given-names>F</given-names></name>, <name><surname>McCarthy</surname><given-names>G</given-names></name> (<year>2006</year>) <article-title>Brain systems mediating cognitive interference by emotional distraction</article-title>. <source>J Neurosci</source>
<volume>26</volume>: <fpage>2072</fpage>–<lpage>2079</lpage>.<pub-id pub-id-type="pmid">16481440</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Kristjansson1">
                <label>40</label>
                <mixed-citation publication-type="journal"><name><surname>Kristjansson</surname><given-names>A</given-names></name>, <name><surname>Oladottir</surname><given-names>B</given-names></name>, <name><surname>Most</surname><given-names>SB</given-names></name> (<year>2013</year>) <article-title>“Hot” facilitation of “cool” processing: Emotional distraction can enhance priming of visual search</article-title>. <source>J Exp Psychol Hum Percept Perform</source>
<volume>39</volume>: <fpage>298</fpage>–<lpage>306</lpage>.<pub-id pub-id-type="pmid">22642218</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Pessoa1">
                <label>41</label>
                <mixed-citation publication-type="journal"><name><surname>Pessoa</surname><given-names>L</given-names></name>, <name><surname>Ungerleider</surname><given-names>LG</given-names></name> (<year>2004</year>) <article-title>Neuroimaging studies of attention and the processing of emotion-laden stimuli</article-title>. <source>Prog Brain Res</source>
<volume>144</volume>: <fpage>171</fpage>–<lpage>182</lpage>.<pub-id pub-id-type="pmid">14650848</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Forscher1">
                <label>42</label>
                <mixed-citation publication-type="journal"><name><surname>Forscher</surname><given-names>EC</given-names></name>, <name><surname>Li</surname><given-names>W</given-names></name> (<year>2012</year>) <article-title>Hemispheric asymmetry and visuo-olfactory integration in perceiving subthreshold (micro) fearful expressions</article-title>. <source>J Neurosci</source>
<volume>32</volume>: <fpage>2159</fpage>–<lpage>2165</lpage>.<pub-id pub-id-type="pmid">22323728</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Pollatos1">
                <label>43</label>
                <mixed-citation publication-type="journal"><name><surname>Pollatos</surname><given-names>O</given-names></name>, <name><surname>Kopietz</surname><given-names>R</given-names></name>, <name><surname>Linn</surname><given-names>J</given-names></name>, <name><surname>Albrecht</surname><given-names>J</given-names></name>, <name><surname>Sakar</surname><given-names>V</given-names></name>, <etal>et al</etal> (<year>2007</year>) <article-title>Emotional stimulation alters olfactory sensitivity and odor judgment</article-title>. <source>Chem Senses</source>
<volume>32</volume>: <fpage>583</fpage>–<lpage>589</lpage>.<pub-id pub-id-type="pmid">17495172</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Miller2">
                <label>44</label>
                <mixed-citation publication-type="journal"><name><surname>Miller</surname><given-names>SS</given-names></name>, <name><surname>Gordon</surname><given-names>AR</given-names></name>, <name><surname>Olsson</surname><given-names>MJ</given-names></name>, <name><surname>Lundstrom</surname><given-names>JN</given-names></name>, <name><surname>Dalton</surname><given-names>P</given-names></name> (<year>2013</year>) <article-title>Mind over age–stereotype activation and olfactory function</article-title>. <source>Chemical senses</source>
<volume>38</volume>: <fpage>167</fpage>–<lpage>174</lpage>.<pub-id pub-id-type="pmid">23118205</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Lundstrom2">
                <label>45</label>
                <mixed-citation publication-type="journal"><name><surname>Lundstrom</surname><given-names>JN</given-names></name>, <name><surname>Mathe</surname><given-names>A</given-names></name>, <name><surname>Schaal</surname><given-names>B</given-names></name>, <name><surname>Frasnelli</surname><given-names>J</given-names></name>, <name><surname>Nitzsche</surname><given-names>K</given-names></name>, <etal>et al</etal> (<year>2013</year>) <article-title>Maternal status regulates cortical responses to the body odor of newborns</article-title>. <source>Frontiers in psychology</source>
<volume>4</volume>: <fpage>597</fpage>.<pub-id pub-id-type="pmid">24046759</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Mitro1">
                <label>46</label>
                <mixed-citation publication-type="journal"><name><surname>Mitro</surname><given-names>S</given-names></name>, <name><surname>Gordon</surname><given-names>AR</given-names></name>, <name><surname>Olsson</surname><given-names>MJ</given-names></name>, <name><surname>Lundstrom</surname><given-names>JN</given-names></name> (<year>2012</year>) <article-title>The smell of age: perception and discrimination of body odors of different ages</article-title>. <source>PloS one</source>
<volume>7</volume>: <fpage>e38110</fpage>.<pub-id pub-id-type="pmid">22666457</pub-id></mixed-citation>
              </ref>
              <ref id="pone.0098347-Vroomen2">
                <label>47</label>
                <mixed-citation publication-type="journal"><name><surname>Vroomen</surname><given-names>J</given-names></name>, <name><surname>Driver</surname><given-names>J</given-names></name>, <name><surname>de Gelder</surname><given-names>B</given-names></name> (<year>2001</year>) <article-title>Is cross-modal integration of emotional expressions independent of attentional resources?</article-title>
<source>Cognitive, affective &amp; behavioral neuroscience</source>
<volume>1</volume>: <fpage>382</fpage>–<lpage>387</lpage>.</mixed-citation>
              </ref>
              <ref id="pone.0098347-Barrett2">
                <label>48</label>
                <mixed-citation publication-type="journal"><name><surname>Barrett</surname><given-names>LF</given-names></name>, <name><surname>Bar</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>See it with feeling: affective predictions during object perception</article-title>. <source>Philosophical transactions of the Royal Society of London Series B, Biological sciences</source>
<volume>364</volume>: <fpage>1325</fpage>–<lpage>1334</lpage>.<pub-id pub-id-type="pmid">19528014</pub-id></mixed-citation>
              </ref>
            </ref-list>
          </back>
        </article>
      </metadata>
    </record>
  </GetRecord>
</OAI-PMH>
